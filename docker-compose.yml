version: '3.8'

services:
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-smoops}
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  backend:
    build: 
      context: ./backend
      dockerfile: Dockerfile
    volumes:
      - ./backend:/app
      - /app/node_modules
    ports:
      - "${PORT:-3001}:3001"
    env_file:
      - .env
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-smoops}?schema=public
      - NODE_ENV=${NODE_ENV:-development}
    depends_on:
      postgres:
        condition: service_healthy
    command: npm run dev

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    volumes:
      - ./frontend:/app
      - /app/node_modules
      - /app/.next
    ports:
      - "${FRONTEND_PORT:-3000}:3000"
    env_file:
      - .env
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:${PORT:-3001}
      - NODE_ENV=${NODE_ENV:-development}
    depends_on:
      - backend
    command: npm run dev

  ml:
    build: 
      context: ./ml
      dockerfile: Dockerfile
    volumes:
      - ./ml:/app
      - /app/__pycache__
    ports:
      - "${ML_PORT:-3002}:3002"
    env_file:
      - .env
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-smoops}?schema=public
      - PYTHONUNBUFFERED=1
    depends_on:
      - postgres
    command: python -m ml.backend.src.scripts.server

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: always
    ports:
      - "11434:11434"
    volumes:
      - /Volumes/abhaskumarrr_ssd/ollama_models:/root/.ollama
    environment:
      - OLLAMA_MODELS=/root/.ollama
    # Pulls models to external SSD for persistence and performance
    # To use a different model, set OLLAMA_DEFAULT_MODEL=phi4 or phi3 as needed

  questdb:
    image: questdb/questdb:7.3.10
    container_name: questdb
    ports:
      - "${QUESTDB_HTTP_PORT:-9000}:9000"  # HTTP/REST API and Web Console
      - "${QUESTDB_PG_PORT:-8812}:8812"    # PostgreSQL wire protocol
      - "${QUESTDB_ILP_PORT:-9009}:9009"   # InfluxDB Line Protocol (high-performance ingestion)
    volumes:
      - questdb_data:/var/lib/questdb
    environment:
      - QDB_CAIRO_COMMIT_LAG=1000
      - QDB_CAIRO_MAX_UNCOMMITTED_ROWS=10000
      - QDB_SHARED_WORKER_COUNT=2
      - QDB_HTTP_WORKER_COUNT=2
      - QDB_HTTP_WORKER_AFFINITY=false
      - QDB_HTTP_WORKER_HALTONFAILURE=false
      - QDB_PG_ENABLED=true
      - QDB_PG_NET_ACTIVE_CONNECTION_LIMIT=10
      - QDB_LINE_TCP_ENABLED=true
      - QDB_LINE_TCP_NET_ACTIVE_CONNECTION_LIMIT=10
      - QDB_TELEMETRY_ENABLED=false
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9000/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: unless-stopped

volumes:
  postgres_data:
  questdb_data:
